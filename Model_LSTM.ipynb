{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nimport datetime\nimport gc\n\nfrom sklearn.model_selection import train_test_split,KFold\nfrom sklearn.metrics import mean_squared_error\n\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\n\n%matplotlib inline\nfrom sklearn.linear_model import (LinearRegression, Ridge, Lasso,LogisticRegression)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n\n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        \n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef missing_statistics(df):    \n    statitics = pd.DataFrame(df.isnull().sum()).reset_index()\n    statitics.columns=['COLUMN NAME',\"MISSING VALUES\"]\n    statitics['TOTAL ROWS'] = df.shape[0]\n    statitics['% MISSING'] = round((statitics['MISSING VALUES']/statitics['TOTAL ROWS'])*100,2)\n    return statitics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training = import_data('/kaggle/input/pre-processing/data_training.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitted data \ndf_val = import_data('/kaggle/input/testval-processing/df_val.csv')\ntraining= import_data('/kaggle/input/testval-processing/df_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = import_data('/kaggle/input/testval-processing/data_test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_val.shape[0],training.shape[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_statistics(data_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n#training['timestamp'] = pd.to_datetime(training.timestamp, format='%Y-%m-%d %H:%M:%S')\n#training['timestamp'] = pd.to_numeric(training['timestamp'])\ntraining.primary_use = le.fit_transform(training.primary_use)\ntraining.set_index(['hour', 'month'], inplace=True) \n\ndf_val.primary_use = le.fit_transform(df_val.primary_use)\ndf_val.set_index(['hour', 'month'], inplace=True)\n\n#data_test['timestamp'] = pd.to_datetime(data_test.timestamp, format='%Y-%m-%d %H:%M:%S')\n#data_test['timestamp'] = pd.to_numeric(data_test['timestamp'])\ndata_test.primary_use = le.fit_transform(data_test.primary_use)\ndata_test.set_index(['hour', 'month'], inplace=True)\ntraining","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\n#training = training.sample(frac = 1) \n\nx_train = training[['site_id','building_id','meter','primary_use','square_feet','air_temperature',\n            'dew_temperature','wind_direction','wind_speed','sea_level_pressure','precip_depth_1_hr']]\n\ny_train = training['meter_reading'] \n\nX_val = df_val[['site_id','building_id','meter','primary_use','square_feet','air_temperature',\n                'dew_temperature','wind_direction','wind_speed','sea_level_pressure','precip_depth_1_hr']]\n#\ny_val = df_val['meter_reading'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.values[:]\nx_train= x_train.reshape((x_train.shape[0],1,x_train.shape[-1]))\n#x_train = np.expand_dims(X,axis = 2)\ny_train = y_train.values\n\n# validation_data=(x_val,y_val)\nx_val = X_val.values[:]\nx_val = x_val.reshape((x_val.shape[0],1,x_val.shape[-1]))\n#x_val = np.expand_dims(X,axis = 2)\ny_val= y_val.values\n\n\n# print(x_train.shape , x_val.shape) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del  training\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.layers import Dense, LSTM, GRU, Dropout, BatchNormalization \nfrom keras.layers.core import Activation\nfrom keras.models import Sequential\nfrom keras.optimizers import RMSprop,Adam\nfrom keras import regularizers\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers \nimport random\nimport os\n\n# Import deep learning layers and functions from tensorflow\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.optimizers import Adam\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es = EarlyStopping(monitor='val_root_mean_squared_error', min_delta=0.0001, patience=2, verbose=True, mode='auto')\n#monitor='val_loss'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.01) # model optimazer with mearning rat eof 0,01\nmy_init = tensorflow.keras.initializers.glorot_uniform(seed=1) # features weights initializer\n#input_dim=x_train.shape[-1]\nmodel = tensorflow.keras.Sequential([\n            tensorflow.keras.layers.LSTM(120,return_sequences=True ,activation='relu',kernel_initializer=my_init ,input_shape=(None,x_train.shape[-1])),\n            tensorflow.keras.layers.Dropout(0.4),\n            tensorflow.keras.layers.LSTM(128,return_sequences=False),\n            tensorflow.keras.layers.Dropout(0.4),\n            tensorflow.keras.layers.Dense(1) ])\n#,activation='relu',kernel_initializer=my_init","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=opt, loss='mean_squared_error',metrics=['accuracy']) #Adam(learning_rate=0.001) : this is the default learning rate of adam,metrics=[metrics]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, epochs=80, batch_size=8000, validation_data=(x_val,y_val) ,verbose=1,callbacks = es); # include callbacks_list to callbacks parameter\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from numpy import sqrt\n# mse = model.evaluate(x_val, y_val, verbose=0)\n# print('MSE: %.3f, RMSE: %.3f ' % (mse[1], sqrt(mse[1])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = data_test[['site_id','building_id','meter','primary_use','square_feet','air_temperature',\n                 'dew_temperature','sea_level_pressure','wind_direction','wind_speed','precip_depth_1_hr']]\n\ntest_data = test_data.values[:]\ntest_data= test_data.reshape((test_data.shape[0],1,test_data.shape[-1]))\n#test_data = np.expand_dims(test_data,axis = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" submission=pd.read_csv('/kaggle/input/ashrae-energy-prediction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x_train , y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_predict=model.predict(test_data)\nf_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data= test_data.reshape((test_data.shape[0],test_data.shape[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = np.concatenate((test_data, f_predict), axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test_data , f_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subdf = pd.DataFrame(test,columns=['site_id','building_id','meter','primary_use','square_feet','air_temperature',\n                 'dew_temperature','sea_level_pressure','wind_direction','wind_speed','precip_depth_1_hr','meter_reading'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del  test ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_to_convtest = subdf[subdf['site_id']==0].index #Convertir les prÃ©dictions du site_id  0 \nfor j in data_to_convtest :\n    subdf.at[j,'meter_reading']=(subdf.at[j,'meter_reading']*3.4118)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# submition data"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['meter_reading'] = subdf['meter_reading'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del  subdf , data_to_convtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['meter_reading'].clip(lower=0,upper=None,inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('LSTM_Sub.csv',index = False)\nsubmission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}